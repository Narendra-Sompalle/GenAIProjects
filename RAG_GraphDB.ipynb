{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPpnUYPDqAjJeYv4UGfL7qC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Narendra-Sompalle/GenAIProjects/blob/main/RAG_GraphDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "VtTbTucRY9fX"
      },
      "outputs": [],
      "source": [
        "! pip install --upgrade --quiet langchain langchain-community langchain_groq neo4j langchain_experimental langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NEO4J_URI=\"\"\n",
        "NEO4J_USERNAME=\"\"\n",
        "NEO4J_PASSWORD=\"\""
      ],
      "metadata": {
        "id": "BFxu8akuZVyk"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "n78G3kzChecH"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"NEO4J_URI\"] = NEO4J_URI\n",
        "os.environ[\"NEO4J_USERNAME\"] = NEO4J_USERNAME\n",
        "os.environ[\"NEO4J_PASSWORD\"] = NEO4J_PASSWORD"
      ],
      "metadata": {
        "id": "_x1EG9tUhwus"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.graphs import Neo4jGraph"
      ],
      "metadata": {
        "id": "MhPq06vRh1hY"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Neo=Neo4jGraph(\n",
        "    url=os.environ.get(\"NEO4J_URI\"),\n",
        "    username=os.environ.get(\"NEO4J_USERNAME\"),\n",
        "    password=os.environ.get(\"NEO4J_PASSWORD\"),\n",
        ")\n"
      ],
      "metadata": {
        "id": "RI_6TKT9iREh"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "b8fj4Q8rThlT"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai.llms import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "pf9pBgvViZCC"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=ChatGoogleGenerativeAI(temperature=1,model=\"gemini-2.0-flash\",api_key=\"\")"
      ],
      "metadata": {
        "id": "O9Hv_D6ME4i7"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.graph_transformers import LLMGraphTransformer"
      ],
      "metadata": {
        "id": "H03YOPyDSDbG"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_trans=LLMGraphTransformer(llm=llm)"
      ],
      "metadata": {
        "id": "7XgWZdWVFIZX"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "text=\"\"\"Use server-side calls with API keys The most secure way to use your API key is to call the Gemini API from a server-side application where the key can be kept confidential.\n",
        "\n",
        "Use ephemeral tokens for client-side access (Live API only): For direct client-side access to the Live API, you can use ephemeral tokens. They come with lower security risks and can be suitable for production use. Review ephemeral tokens guide for more information.\"\"\""
      ],
      "metadata": {
        "id": "vlvECcCaTGXO"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document=Document(page_content=text)"
      ],
      "metadata": {
        "id": "X1jGqyYmWFq_"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trans=graph_trans.convert_to_graph_documents([document])"
      ],
      "metadata": {
        "id": "br4a9sGfWIJ8"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK4IFKO6WMUJ",
        "outputId": "2f056982-a1c8-43d5-bdda-f4fd97216d53"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[GraphDocument(nodes=[Node(id='Gemini Api', type='Api', properties={}), Node(id='Api Key', type='Key', properties={}), Node(id='Ephemeral Tokens', type='Token', properties={}), Node(id='Live Api', type='Api', properties={})], relationships=[Relationship(source=Node(id='Gemini Api', type='Api', properties={}), target=Node(id='Api Key', type='Key', properties={}), type='USES', properties={}), Relationship(source=Node(id='Live Api', type='Api', properties={}), target=Node(id='Ephemeral Tokens', type='Token', properties={}), type='USES', properties={})], source=Document(metadata={}, page_content='Use server-side calls with API keys The most secure way to use your API key is to call the Gemini API from a server-side application where the key can be kept confidential.\\n\\nUse ephemeral tokens for client-side access (Live API only): For direct client-side access to the Live API, you can use ephemeral tokens. They come with lower security risks and can be suitable for production use. Review ephemeral tokens guide for more information.'))]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Load the dataset of movie\n",
        "\n",
        "movie_query=\"\"\"\n",
        "LOAD CSV WITH HEADERS FROM\n",
        "'https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/movies/movies_small.csv' as row\n",
        "\n",
        "MERGE(m:Movie{id:row.movieId})\n",
        "SET m.released = date(row.released),\n",
        "    m.title = row.title,\n",
        "    m.imdbRating = toFloat(row.imdbRating)\n",
        "FOREACH (director in split(row.director, '|') |\n",
        "    MERGE (p:Person {name:trim(director)})\n",
        "    MERGE (p)-[:DIRECTED]->(m))\n",
        "FOREACH (actor in split(row.actors, '|') |\n",
        "    MERGE (p:Person {name:trim(actor)})\n",
        "    MERGE (p)-[:ACTED_IN]->(m))\n",
        "FOREACH (genre in split(row.genres, '|') |\n",
        "    MERGE (g:Genre {name:trim(genre)})\n",
        "    MERGE (m)-[:IN_GENRE]->(g))\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "YqonWiVTWnhH"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Neo.query(movie_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48uYelxLcfpH",
        "outputId": "7cfed9aa-0f9f-4735-b262-ed73ad002c8e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import GraphCypherQAChain\n",
        "chain=GraphCypherQAChain.from_llm(llm=llm,graph=Neo,verbose=False,allow_dangerous_requests=True)"
      ],
      "metadata": {
        "id": "tEae9jGUiwdH"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Afhlbq-k7y8",
        "outputId": "220c7f96-64d5-42cc-f2f4-c0767ef985c6"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GraphCypherQAChain(verbose=False, graph=<langchain_community.graphs.neo4j_graph.Neo4jGraph object at 0x7cc442f16990>, cypher_generation_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question', 'schema'], input_types={}, partial_variables={}, template='Task:Generate Cypher statement to query a graph database.\\nInstructions:\\nUse only the provided relationship types and properties in the schema.\\nDo not use any other relationship types or properties that are not provided.\\nSchema:\\n{schema}\\nNote: Do not include any explanations or apologies in your responses.\\nDo not respond to any questions that might ask anything else than for you to construct a Cypher statement.\\nDo not include any text except the generated Cypher statement.\\n\\nThe question is:\\n{question}'), llm=ChatGoogleGenerativeAI(model='models/gemini-2.0-flash', google_api_key=SecretStr('**********'), temperature=1.0, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x7cc44183ccd0>, default_metadata=(), model_kwargs={}), output_parser=StrOutputParser(), llm_kwargs={}), qa_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant that helps to form nice and human understandable answers.\\nThe information part contains the provided information that you must use to construct an answer.\\nThe provided information is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\\nMake the answer sound as a response to the question. Do not mention that you based the result on the given information.\\nHere is an example:\\n\\nQuestion: Which managers own Neo4j stocks?\\nContext:[manager:CTL LLC, manager:JANE STREET GROUP LLC]\\nHelpful Answer: CTL LLC, JANE STREET GROUP LLC owns Neo4j stocks.\\n\\nFollow this example when generating answers.\\nIf the provided information is empty, say that you don't know the answer.\\nInformation:\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\"), llm=ChatGoogleGenerativeAI(model='models/gemini-2.0-flash', google_api_key=SecretStr('**********'), temperature=1.0, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x7cc44183ccd0>, default_metadata=(), model_kwargs={}), output_parser=StrOutputParser(), llm_kwargs={}), graph_schema='Node properties are the following:\\nPerson {born: INTEGER, name: STRING}\\nRelationship properties are the following:\\n\\nThe relationships are the following:\\n', allow_dangerous_requests=True)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"give me only director name don't give extra content, who is director of Jumanji\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8L1-2dKslGRm",
        "outputId": "159501dd-58ce-40e8-a258-105d8be527ca"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': \"give me only director name don't give extra content, who is director of Jumanji\",\n",
              " 'result': 'Joe Johnston'}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I2GQJTKJln4j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}